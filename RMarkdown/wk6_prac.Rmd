---
title: "wk6"
author: "Yun Zhao"
date: "11/16/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Blue Plaques
For any given London Borough, are the Blue Plaques within that borough distributed randomly or do they exhibit some kind of dispersed or clustered pattern?
```{r packages, include = False}
#Wrangling Munging
library(here)
library(janitor)
library(dplyr)
library(stringr)
library(tidyverse)

#Geo
library(sf)
library(sp)
library(rgeos)
library(geojson)
library(geojsonio)
library(raster)
library(fpc)
library(spatstat)
library(spdep)

#Plotting
library(maptools)
library(tmap)
library(tmaptools)
library(GISTools)
library(OpenStreetMap)
```

https://r4ds.had.co.nz/strings.html
Anchors: Begin with power (^), end with Money ($)

## Load Data: Clip Blue Plaques points to London Boroughs map
Alternate sources:
https://opendata.arcgis.com/datasets/8edafbe3276d4b56aec60991cbddda50_4.geojson
https://s3.eu-west-2.amazonaws.com/openplaques/open-plaques-london-2018-04-08.geojson
```{r}
#LondonBoroughs <- st_read("")
LondonBoroughs <- st_read(here::here("Shapefiles", "statistical-gis-boundaries-london", "ESRI", 
                                     "London_Borough_Excluding_MHW.shp"))
BoroughMap <- LondonBoroughs %>%
  dplyr::filter(str_detect(GSS_CODE, "^E09"))%>%
  st_transform(., 27700)
#qtm(LondonBoroughs)
qtm(BoroughMap)

BluePlaques <- st_read(here::here("GeoJSONs", "open-plaques-london-2018-04-08.geojson"))%>%
  st_transform(.,27700)
#summary(BluePlaques)
#plot on LondonBoroughs
tmap_mode("plot") 
tm_shape(BoroughMap) + 
  tm_polygons(col = NA, alpha = 0.5) +
tm_shape(BluePlaques) + 
  tm_dots(col = "blue")

BluePlaques

#remove duplicates, which cause points out of boroughs
BluePlaques <- distinct(BluePlaques)
#Spatial subsetting: clip to London Bouroughs map borders. can use as st_filter
BluePlaquesSub <- BluePlaques[BoroughMap,]
#check to see that they've been removed
tmap_mode("plot")
tm_shape(BoroughMap) +
  tm_polygons(col = NA, alpha = 0.5) +
tm_shape(BluePlaquesSub) +
  tm_dots(col = "blue")
```


## Harrow Borough
```{r extract borough}
#extract the borough
Harrow <- BoroughMap %>%
  filter(., NAME=="Harrow")
#Check to see that the correct borough has been pulled out
tm_shape(Harrow) +
  tm_polygons(col = NA, alpha = 0.5)

# clip BluePlaquesSub to Harrow borough
BluePlaquesSub<-BluePlaquesSub[Harrow,]
# view
tm_shape(Harrow) +
  tm_polygons(col = NA, alpha = 0.5) +
tm_shape(BluePlaquesSub) +
  tm_dots(col = 'blue')
```


## Using Spatstat library: observation window, ppp object
windows are like a bounding box
```{r}
# create an observation window for spatstat to the extent of Harrow borough boundary
window <- as.owin(Harrow)
plot(window)

# from sf to sp object
BluePlaquesSub<- BluePlaquesSub %>%
  as(., 'Spatial') 

# from sp to ppp object (point pattern object)
BluePlaquesSub.ppp <- ppp(x=BluePlaquesSub@coords[,1],
                          y=BluePlaquesSub@coords[,2],
                          window=window)
# plot ppp in window
BluePlaquesSub.ppp %>%
  plot(.,pch=16,cex=0.5, 
       main="Blue Plaques Harrow")

# Kernel Density Estimation
BluePlaquesSub.ppp %>%
  density(., sigma=500) %>%
  plot()
```
## Quadrat Analysis and Poisson distribution
```{r}
#First plot the points
plot(BluePlaquesSub.ppp,
     pch=16,
     cex=0.5, #the amount by which plotting characters and symbols should be scaled relative to the default
     main="Blue Plaques in Harrow")

#now count the points in that fall in a 6 x 6 grid overlaid across the window
BluePlaquesSub.ppp %>%
  quadratcount(.,nx = 6, ny = 6)%>% 
    plot(., add=T, col="red")

#save a table of the quadrat count
Qcount <- BluePlaquesSub.ppp %>%
  quadratcount(.,nx = 6, ny = 6) %>%
  as.data.frame() %>%
  dplyr::count(Var1=Freq)%>%
  dplyr::rename(Freqquadratcount=n)
Qcount %>%
  summarise_all(class)
Qcount
```
### Compare Observed and Expected Distributions
```{r}
sums <- Qcount %>%
  #calculate the total blue plaques (Var * Freq)
  mutate(total = Var1 * Freqquadratcount) %>%
  dplyr::summarise(across(everything(), sum))%>%
  dplyr::select(-Var1) 

lambda<- Qcount%>%
  #calculate lambda
  mutate(total = Var1 * Freqquadratcount)%>%
  dplyr::summarise(across(everything(), sum)) %>%
  mutate(lambda=total/Freqquadratcount) %>%
  dplyr::select(lambda)%>%
  pull(lambda) #gets rid of a row name. extracts single column, like $. nice in pipes

QCountTable <- Qcount %>%
  # Calculate expected CSR distribution iusing the Poisson formula
  mutate(Pr=((lambda^Var1)*exp(-lambda))/factorial(Var1))%>%
  # Calculate the expected counts based on total number of plaques
  mutate(Expected= (round(Pr * sums$Freqquadratcount, 0)))

#Compare the frequency distributions of the observed and expected point patterns
plot(c(1,5),c(0,14), type="n",
xlab="Number of Blue Plaques (Red=Observed,Blue=Expected)", 
     ylab="Frequency of Occurances")
points(QCountTable$Freqquadratcount, 
       col="Red", 
       type="o", 
       lwd=3)
points(QCountTable$Expected, col="Blue", 
       type="o", 
       lwd=3)

# Chi- squared
teststats <- quadrat.test(BluePlaquesSub.ppp, nx = 6, ny = 6)
teststats
plot(BluePlaquesSub.ppp,pch=16,cex=0.5, main="Blue Plaques in Harrow")
plot(teststats, add=T, col = "red")

?quadrat.test
```
Higher frequency counts at the lower end — something reminiscent of a Poisson distribution. 
This could indicate that for this particular set of quadrants, our pattern is close to Complete Spatial Randomness

Note the warning message — some of the observed counts are very small (0) and this may affect the accuracy of the quadrant test. Recall that the Poisson distribution only describes observed occurrances that are counted in integers — where our occurrences = 0 (i.e. not observed), this can be an issue. We also know that there are various other problems that might affect our quadrat analysis, such as the modifiable areal unit problem. 



## Ripley's K
Compare the observed distribution of points with the Poisson random model 
for a whole range of different distance radii. 
sum clustering. Rings around points rather than squares.

```{r}
K <- BluePlaquesSub.ppp %>%
  # the correction specifies how points towards the edge are dealt with, in this case, border means that points towards the edge are ignored for the calculation but are included for the central points.
  Kest(., correction="border") %>%
  plot()

# save results
Kval <- as.data.frame(Kest(BluePlaquesSub.ppp, correction = "border"))
```
peak saround 1200ml, with the largest bulge around 700m


## DBSCAN

but where are the pts clustering? use dbscan. ...just map the pts themselves rather than...
local indices of spatial autocorelation and friends
  needs spatial weight matrix. neighboring polygons.
  colorbrewer
  
1. Epsilon - this is the radius within which the algorithm with search for clusters 
                    starting with Ripley's K peak, why???
2. MinPts - this is the minimum number of points that should be considered a cluster
```{r}
#first check the coordinate reference system of the Harrow spatial polygon:
st_geometry(BoroughMap)
  
#first extract the points from the spatial points data frame ???????
BluePlaquesSubPoints <- BluePlaquesSub %>%
  coordinates(.)%>%
  as.data.frame()

#now run the dbscan analysis
db <- BluePlaquesSubPoints %>%
  fpc::dbscan(.,eps = 700, MinPts = 4)

#now plot the results
plot(db, BluePlaquesSubPoints, main = "DBSCAN Output", frame = F)
plot(BoroughMap$geometry, add=T)
```
???????
```{r}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
library(dbscan)

BluePlaquesSubPoints%>%
  dbscan::kNNdistplot(.,k=4)

library(ggplot2)
```

```{r}
print(db)
print(db$cluster)

#whyyy
BluePlaquesSubPoints<- BluePlaquesSubPoints %>%
  mutate(dbcluster=db$cluster)
```

```{r}
chulls <- BluePlaquesSubPoints %>%
  group_by(dbcluster) %>%
  dplyr::mutate(hull = 1:n(),
  hull = factor(hull, chull(coords.x1, coords.x2)))%>%
  arrange(hull)

#chulls2 <- ddply(BluePlaquesSubPoints, .(dbcluster), 
              #  function(df) df[chull(df$coords.x1, df$coords.x2), ])

# Drop 0 : isn’t actually a cluster (it’s all points that aren’t in a cluster) 
chulls <- chulls %>%
  filter(dbcluster >=1)

```

```{r}
dbplot <- ggplot(data=BluePlaquesSubPoints, 
                 aes(coords.x1,coords.x2, colour=dbcluster, fill=dbcluster)) 
#add the points in
dbplot <- dbplot + geom_point()
#now the convex hulls
dbplot <- dbplot + geom_polygon(data = chulls, 
                                aes(coords.x1,coords.x2, group=dbcluster), 
                                alpha = 0.5) 
#now plot, setting the coordinates to scale correctly and as a black and white plot 
#(just for the hell of it)...
dbplot + theme_bw() + coord_equal()
```

Nina

#convex hulls to wrap around points
chulls <- data.frame()
for (cluster in 1:max(BluePlaquesSubPoints$dbcluster)) {
  cluster_data <- BluePlaquesSubPoints %>%
    filter(dbcluster == cluster)
  ch <- chull(cluster_data$coords.x1, cluster_data$coords.x2)
  chulls <- chulls %>%
    bind_rows(cluster_data[c(ch), ])
}

```{r}
###add a basemap
##First get the bbox in lat long for Harrow. ?????why
HarrowWGSbb <- Harrow %>%
  st_transform(., 4326)%>%   
  st_bbox()



#basemap <- OpenStreetMap::openmap(c(51.5549876,-0.4040502),c(51.6405356,-0.2671315),
                        # zoom=NULL,
                      #   "stamen-toner")

  # convert the basemap to British National Grid
#basemap_bng <- openproj(basemap, projection="+init=epsg:27700")
```

#autoplot(basemap_bng) sometimes works
autoplot.OpenStreetMap(basemap_bng)+ 
  geom_point(data=BluePlaquesSubPoints, 
             aes(coords.x1,coords.x2, 
                 colour=dbcluster, 
                 fill=dbcluster)) + 
  geom_polygon(data = chulls, 
               aes(coords.x1,coords.x2, 
                   group=dbcluster,
                   fill=dbcluster), 
               alpha = 0.5)  
               
               
               
# Analysing Spatial Autocorrelation with Moran’s I, LISA and friends 

## load data and map to check
```{r}
LondonWardsMerged <- st_read(here::here("Shapefiles", "statistical-gis-boundaries-london", 
                                  "ESRI", "London_Ward_CityMerged.shp"))%>%
  st_transform(.,27700)

WardData <- read_csv(here::here('CSVs', 'ward-profiles-excel-version.csv'),
                     #na = c('NA', 'n/a'),
                     #locale=locale(encoding='latin1')
                     )%>%
  clean_names()
  
LondonWardsMerged <- LondonWardsMerged %>% 
  left_join(., WardData, 
            by = c("GSS_CODE" = "new_code"))%>%
  dplyr::distinct(GSS_CODE, .keep_all = T)%>%
  dplyr::select(GSS_CODE, ward_name, average_gcse_capped_point_scores_2014)

#st_crs(LondonWardsMerged)
#head(LondonWardsMerged)
tmap_mode('view')
tm_shape(LondonWardsMerged)+
  tm_polygons(col = NA, alpha = 0.5)+
tm_shape(BluePlaques)+
  tm_dots(col = 'blue')
```
## spatial join blue plaques to wards; chloropleth map
```{r}
points_sf_joined <- LondonWardsMerged%>%
  st_join(st_as_sf(BluePlaquesSub))%>%
  add_count(ward_name)%>%
  janitor::clean_names()%>%
  mutate(area=st_area(.))%>%
  mutate(density=n/area)%>%
  dplyr::select(density, ward_name, gss_code, n, average_gcse_capped_point_scores_2014)

points_sf_joined<- points_sf_joined %>%                    
  group_by(gss_code) %>%         
  summarise(density = first(density),
          wardname= first(ward_name),
          plaquecount= first(n))


#why first()?

tmap_mode('view')
tm_shape(points_sf_joined) +
    tm_polygons("density",
        style="jenks",
        palette="PuOr",
        midpoint=NA,
        popup.vars=c("wardname", "density"),
        title="Blue Plaque Density")
```


spatial weights matrix
```{r}
#First calculate the centroids of all Wards in London
coordsW <- points_sf_joined%>%
  st_centroid()%>%
  st_geometry()
plot(coordsW,axes=TRUE)

#create a neighbours list with queens case
LWard_nb <- points_sf_joined %>%
  poly2nb(., queen=T)
summary(LWard_nb)

#plot them
plot(LWard_nb, st_geometry(coordsW), col="red")
#add a map underneath
plot(points_sf_joined$geometry, add=T)

#create a spatial weights matrix from these weights
# B = binary coding
Lward.lw <- LWard_nb %>%
  nb2mat(., style="B")
#sum(Lward.lw)
#sum(Lward.lw[,1]) #row standardisation
```


##Moran’s I 
```{r}
#convert matrix to a spatial weight list type object
Lward.lw <- LWard_nb %>%
  nb2listw(., style="C")

I_LWard_Global_Density <- points_sf_joined %>%
  pull(density) %>%
  as.vector()%>%
  moran.test(., Lward.lw)

I_LWard_Global_Density

```
# Getis Ord General G
If G > Expected = High values clustering; if G < expected = low values clustering

remember Geary’s C falls between 0 and 2; 1 means no spatial autocorrelation, <1 - positive spatial autocorrelation or similar values clustering, >1 - negative spatial autocorreation or dissimilar values clustering
```{r}
G_LWard_Global_Density <- 
  points_sf_joined %>%
  pull(density) %>%
  as.vector()%>%
  globalG.test(., Lward.lw)

G_LWard_Global_Density
```
#Local Moran
```{r}
#use the localmoran function to generate I for each ward in the city
I_LWard_Local_count <- points_sf_joined %>%
  pull(plaquecount) %>%
  as.vector()%>%
  localmoran(., Lward.lw)%>%
  as_tibble() # or as database

I_LWard_Local_Density <- points_sf_joined %>%
  pull(density) %>%
  as.vector()%>%
  localmoran(., Lward.lw)%>%
  as_tibble()

#what does the output (the localMoran object) look like?
slice_head(I_LWard_Local_Density, n=5)

#copy some of the columns (the I score (column 1) and the z-score standard deviation (column 4)) back into the LondonWards spatialPolygonsDataframe
points_sf_joined <- points_sf_joined %>%
  mutate(plaque_count_I = as.numeric(I_LWard_Local_count$Ii))%>%
  mutate(plaque_count_Iz =as.numeric(I_LWard_Local_count$Z.Ii))%>%
  mutate(density_I =as.numeric(I_LWard_Local_Density$Ii))%>%
  mutate(density_Iz =as.numeric(I_LWard_Local_Density$Z.Ii))

#set the breaks manually based on the rule that data points >2.58 or <-2.58 standard deviations away from the mean are significant at the 99% level (<1% chance that autocorrelation not present); >1.96 - <2.58 or <-1.96 to >-2.58 standard deviations are significant at the 95% level (<5% change that autocorrelation not present). >1.65 = 90% etc.
breaks1<-c(-1000,-2.58,-1.96,-1.65,1.65,1.96,2.58,1000)

#create a new diverging colour brewer palette and reverse the order so higher values correspond to red
MoranColours<- rev(brewer.pal(8, "RdGy"))

tmap_mode('view')
tm_shape(points_sf_joined) +
    tm_polygons("plaque_count_Iz",
        style="fixed",
        breaks=breaks1,
        palette=MoranColours,
        midpoint=NA,
        title="Local Moran's I, Blue Plaques in London")
```

#Local Getis = Getis Ord G*i statisic for hot and cold spots
```{r}
Gi_LWard_Local_Density <- points_sf_joined %>%
  pull(density) %>%
  as.vector()%>%
  localG(., Lward.lw)

head(Gi_LWard_Local_Density)

points_sf_joined <- points_sf_joined %>%
  mutate(density_G = as.numeric(Gi_LWard_Local_Density))

GIColours<- rev(brewer.pal(8, "RdBu"))

#now plot on an interactive map
tm_shape(points_sf_joined) +
    tm_polygons("density_G",
        style="fixed",
        breaks=breaks1,
        palette=GIColours,
        midpoint=NA,
        title="Gi*, Blue Plaques in London")
```

## Explore other variables
```{r}
#use head to see what other variables are in the data file
slice_head(points_sf_joined, n=2)

Datatypelist <- LondonWardsMerged %>% 
  st_drop_geometry()%>%
  summarise_all(class) %>%
  pivot_longer(everything(), 
               names_to="All_variables", 
               values_to="Variable_class")
Datatypelist

#local moran
I_LWard_Local_GCSE <- LondonWardsMerged %>%
  arrange(GSS_CODE)%>%
  pull(average_gcse_capped_point_scores_2014)%>%
  as.vector()%>%
  localmoran(., Lward.lw)%>%
  as_tibble()

show(Lward.lw)


points_sf_joined <- points_sf_joined %>%
  arrange(gss_code)%>%
  mutate(GCSE_LocIz = as.numeric(I_LWard_Local_GCSE$Z.Ii))


tm_shape(points_sf_joined) +
    tm_polygons("GCSE_LocIz",
        style="fixed",
        breaks=breaks1,
        palette=MoranColours,
        midpoint=NA,
        title="Local Moran's I, GCSE Scores")

#local Gi*
G_LWard_Local_GCSE <- LondonWardsMerged %>%
  dplyr::arrange(GSS_CODE)%>%
  dplyr::pull(average_gcse_capped_point_scores_2014) %>%
  as.vector()%>%
  localG(., Lward.lw)
  #Error in localmoran(., Lward.lw) : . is not a numeric vector
  #https://stackoverflow.com/questions/61369508/is-vectorx-is-not-true
  #error due to divide by zeros?
summary(Lward.lw)

points_sf_joined <- points_sf_joined %>%
  dplyr::arrange(gss_code)%>%
  dplyr::mutate(GCSE_LocGiz = as.numeric(G_LWard_Local_GCSE))

tm_shape(points_sf_joined) +
    tm_polygons("GCSE_LocGiz",
        style="fixed",
        breaks=breaks1,
        palette=GIColours,
        midpoint=NA,
        title="Gi*, GCSE Scores")
```











               








